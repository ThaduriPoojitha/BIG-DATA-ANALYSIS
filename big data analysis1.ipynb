{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkntNoMxXc03",
        "outputId": "3644bd55-2ffb-4fad-9f5d-b90cc5155767"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“„ Dataset Schema:\n",
            "root\n",
            " |-- category: string (nullable = true)\n",
            " |-- price: integer (nullable = true)\n",
            "\n",
            "\n",
            "ðŸ“Š Sample Data:\n",
            "+--------+-----+\n",
            "|category|price|\n",
            "+--------+-----+\n",
            "|   Books|  150|\n",
            "| Grocery|  300|\n",
            "|   Books|  200|\n",
            "| Grocery|  250|\n",
            "| Fashion|  400|\n",
            "+--------+-----+\n",
            "\n",
            "\n",
            "ðŸ”¢ Count by Category:\n",
            "+--------+-----+\n",
            "|category|Total|\n",
            "+--------+-----+\n",
            "| Grocery|    2|\n",
            "|   Books|    2|\n",
            "| Fashion|    1|\n",
            "+--------+-----+\n",
            "\n",
            "\n",
            "ðŸ’° Average Price:\n",
            "+-------------+\n",
            "|Average Price|\n",
            "+-------------+\n",
            "|        260.0|\n",
            "+-------------+\n",
            "\n",
            "\n",
            "ðŸ“ˆ Min and Max Price:\n",
            "+---------+---------+\n",
            "|Min Price|Max Price|\n",
            "+---------+---------+\n",
            "|      150|      400|\n",
            "+---------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Install PySpark\n",
        "!pip install -q pyspark\n",
        "\n",
        "# Import required libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import avg, count, min, max\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "\n",
        "# Create Spark session\n",
        "spark = SparkSession.builder.appName(\"BigDataNoUpload\").getOrCreate()\n",
        "\n",
        "# Create sample data\n",
        "data = [\n",
        "    (\"Books\", 150),\n",
        "    (\"Grocery\", 300),\n",
        "    (\"Books\", 200),\n",
        "    (\"Grocery\", 250),\n",
        "    (\"Fashion\", 400)\n",
        "]\n",
        "\n",
        "# Define schema\n",
        "schema = StructType([\n",
        "    StructField(\"category\", StringType(), True),\n",
        "    StructField(\"price\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(data, schema=schema)\n",
        "\n",
        "# Show schema and data\n",
        "print(\"ðŸ“„ Dataset Schema:\")\n",
        "df.printSchema()\n",
        "print(\"\\nðŸ“Š Sample Data:\")\n",
        "df.show()\n",
        "\n",
        "# Count records per category\n",
        "print(\"\\nðŸ”¢ Count by Category:\")\n",
        "df.groupBy(\"category\").agg(count(\"*\").alias(\"Total\")).show()\n",
        "\n",
        "# Average price\n",
        "print(\"\\nðŸ’° Average Price:\")\n",
        "df.select(avg(\"price\").alias(\"Average Price\")).show()\n",
        "\n",
        "# Min and Max price\n",
        "print(\"\\nðŸ“ˆ Min and Max Price:\")\n",
        "df.select(min(\"price\").alias(\"Min Price\"), max(\"price\").alias(\"Max Price\")).show()\n",
        "\n",
        "# Stop Spark session\n",
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
